#! /usr/bin/env python
#  -*- coding: utf-8 -*-
#
# Support module generated by PAGE version 6.0.1
#  in conjunction with Tcl version 8.6
#    Apr 28, 2021 02:08:10 PM CEST  platform: Windows NT

import sys
from spacy import displacy
import spacy
import requests
from bs4 import BeautifulSoup
import pandas as pd
import pickle
import os

try:
    import Tkinter as tk
except ImportError:
    import tkinter as tk

try:
    import ttk
    py3 = False
except ImportError:
    import tkinter.ttk as ttk
    py3 = True

def url_to_transcript(url):
    '''Returns transcript data specifically from scrapsfromtheloft.com.'''
    page = requests.get(url).text
    soup = BeautifulSoup(page, "lxml")
    text = [p.text for p in soup.find(class_="mw-content-ltr")]
    #print(url)
    return text

def set_Tk_var():
    global urlLabel
    urlLabel = tk.StringVar()

def init(top, gui, *args, **kwargs):
    global w, top_level, root
    w = gui
    top_level = top
    root = top

def urlButton():
    url = urlLabel.get()
    split_txt = url.split(":")
    if split_txt[0] == "https":
        urls = []
        urls.append(url)
        transcripts = [url_to_transcript(u) for u in urls]
        hardwares = ["hardware"]

        for i, c in enumerate(hardwares):  # creating the txt file to load the data
            with open(c + ".txt", "wb") as file:
                pickle.dump(transcripts[i], file)

        data = {}
        for i, c in enumerate(hardwares):
            with open(c + ".txt", "rb") as file:
                data[c] = pickle.load(file)

        def combine_text(list_of_text):
            '''Takes a list of text and combines them into one large chunk of text.'''
            combined_text = ' '.join(list_of_text)
            return combined_text

        data_combined = {key: [combine_text(value)] for (key, value) in data.items()}

        pd.set_option('max_colwidth', 150)
        data_df = pd.DataFrame.from_dict(data_combined).transpose()
        data_df.columns = ['transcript']
        data_df = data_df.sort_index()

        import re
        import string

        def clean_text_round1(text):
            '''Make text lowercase, remove text in square brackets, remove punctuation and remove words containing numbers.'''
            text = text.lower()
            text = re.sub('\[.*?\]', '', text)
            text = re.sub('[%s]' % re.escape(string.punctuation), '', text)
            return text

        round1 = lambda x: clean_text_round1(x)

        data_clean = pd.DataFrame(data_df.transcript.apply(round1))

        def clean_text_round2(text):
            '''Get rid of some additional punctuation and non-sensical text that was missed the first time around.'''
            text = re.sub('[‘’“”…]', '', text)
            text = re.sub('\n', ' ', text)
            # text = re.sub('\w*\d\w*', '', text)
            return text

        round2 = lambda x: clean_text_round2(x)

        data_clean = pd.DataFrame(data_clean.transcript.apply(round2))
        # print(data_clean)

        cleaned_transcripts = [data_clean.transcript.loc[i] for i in hardwares]

        for i, c in enumerate(hardwares):
            with open(c + ".txt", "w", encoding='utf-8') as file:
                file.write(cleaned_transcripts[i])

        for i, c in enumerate(hardwares):
            with open(c + ".txt", "r", encoding='utf-8') as file:
                example = file.read()

        print("I got the corpus")
        nlp = spacy.load("./best_model")
        print("NER loaded")
        doc = nlp(example)

        html = displacy.render(doc, style='ent')
        with open("data_visualisation3.html", "w", encoding='utf-8') as file:
            file.write(html)
        print("html page created")
        file.close()

        import webbrowser
        new = 2
        url = os.getcwd() + '/data_visualisation3.html'
        webbrowser.open(url, new=new)
        print("html page opened")
        sys.stdout.flush()
    else:
        example = url
        print("I got the corpus")
        nlp = spacy.load("./best_model")
        print("NER loaded")
        doc = nlp(example)

        html = displacy.render(doc, style='ent')
        with open("data_visualisation3.html", "w") as file:
            file.write(html)
        print("html page created")
        file.close()

        import webbrowser
        new = 2
        url = os.getcwd() + '/data_visualisation3.html'
        print(url)
        webbrowser.open(url, new=new)
        print("html page opened")
        sys.stdout.flush()

def destroy_window():
    # Function which closes the window.
    global top_level
    top_level.destroy()
    top_level = None

if __name__ == '__main__':
    import runModel3
    runModel3.vp_start_gui()




